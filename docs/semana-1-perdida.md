# P√©rdida (Loss Functions)

En Machine Learning, una **funci√≥n de p√©rdida** (o *Loss Function*) es una de las piezas m√°s importantes del rompecabezas. Su trabajo es medir qu√© tan "equivocadas" est√°n las predicciones de nuestro modelo en comparaci√≥n con los resultados reales.

!!! info "Analog√≠a Simple üéØ"
    Imagina que est√°s aprendiendo a lanzar dardos. La **funci√≥n de p√©rdida** es como una regla que mide la distancia entre donde aterriz√≥ tu dardo (la predicci√≥n) y el centro del tablero (el valor real). El objetivo del entrenamiento es usar esa medida para ajustar tu lanzamiento y minimizar la distancia en el futuro.

Las funciones de p√©rdida se dividen principalmente en dos categor√≠as, dependiendo del tipo de problema que est√©s resolviendo.

---
## ## 1. Funciones de P√©rdida para Regresi√≥n

Se utilizan cuando el objetivo es predecir un valor num√©rico continuo (ej. el precio de una casa, la temperatura de ma√±ana).

### ### Error Cuadr√°tico Medio (MSE - Mean Squared Error)

Es la funci√≥n de p√©rdida m√°s com√∫n para problemas de regresi√≥n. Calcula el promedio de los errores al cuadrado.

* **F√≥rmula:**
    $$
    MSE = \frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2
    $$
* **¬øC√≥mo funciona?** Al elevar el error al cuadrado, penaliza mucho m√°s los errores grandes. Si tu modelo predice un precio de una casa por $100,000 de diferencia, el MSE lo considerar√° un error mucho peor que 10 errores de $10,000.
* **Cu√°ndo usarlo:** Es ideal cuando los errores grandes son particularmente indeseables y no tienes demasiados valores at√≠picos (*outliers*) en tus datos.

### ### Error Absoluto Medio (MAE - Mean Absolute Error)

Calcula el promedio de los errores en su valor absoluto, sin elevarlos al cuadrado.

* **F√≥rmula:**
    $$
    MAE = \frac{1}{n} \sum_{i=1}^{n} |y_i - \hat{y}_i|
    $$
* **¬øC√≥mo funciona?** Trata todos los errores por igual, sin importar su magnitud. Un error de $100,000 es simplemente el doble de malo que un error de $50,000.
* **Cu√°ndo usarlo:** Es una excelente opci√≥n cuando tus datos tienen valores at√≠picos (*outliers*), ya que es mucho m√°s robusto y menos sensible a ellos que el MSE.

---
## ## 2. Funciones de P√©rdida para Clasificaci√≥n

Se utilizan cuando el objetivo es predecir una categor√≠a (ej. 'perro' o 'gato'; 'spam' o 'no spam').

### ### Entrop√≠a Cruzada Binaria (Binary Cross-Entropy)

Es la funci√≥n de p√©rdida por defecto para problemas de **clasificaci√≥n binaria** (cuando solo hay dos clases posibles).

* **F√≥rmula:**
    $$
    BCE = - \frac{1}{N} \sum_{i=1}^{N} [y_i \log(\hat{y}_i) + (1 - y_i) \log(1 - \hat{y}_i)]
    $$
* **¬øC√≥mo funciona?** Mide qu√© tan lejos est√° la probabilidad predicha por el modelo (un n√∫mero entre 0 y 1) de la etiqueta real (que es 0 o 1). Penaliza fuertemente al modelo cuando est√° muy seguro de una predicci√≥n incorrecta.
* **Cu√°ndo usarlo:** Siempre que tengas un problema con dos resultados posibles, como detecci√≥n de fraude (`fraude` / `no fraude`) o diagn√≥stico m√©dico (`enfermo` / `sano`).

### ### Entrop√≠a Cruzada Categ√≥rica (Categorical Cross-Entropy)

Es la extensi√≥n de la anterior, pero para problemas de **clasificaci√≥n multiclase** (cuando hay m√°s de dos categor√≠as).

* **F√≥rmula:**
    $$
    CCE = - \sum_{i=1}^{C} y_i \log(\hat{y}_i)
    $$
* **¬øC√≥mo funciona?** Compara la distribuci√≥n de probabilidades que el modelo predice para todas las clases con la distribuci√≥n real (donde solo la clase correcta tiene una probabilidad de 1).
* **Cu√°ndo usarlo:** Cuando necesites clasificar algo en una de varias categor√≠as, como reconocer d√≠gitos escritos a mano (clases del 0 al 9) o clasificar im√°genes de animales (`perro` / `gato` / `p√°jaro`).